{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install redis\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more informations on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21eda905be71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mredis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurrent_app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'redis'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import redis\n",
    "from flask import current_app\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info(msg):\n",
    "    current_app.logger.info(msg)\n",
    "\n",
    "\n",
    "class ContentEngine(object):\n",
    "\n",
    "    SIMKEY = 'p:smlr:%s'\n",
    "\n",
    "    def __init__(self):\n",
    "        self._r = redis.StrictRedis.from_url(current_app.config['REDIS_URL'])\n",
    "\n",
    "    def train(self, data_source):\n",
    "        start = time.time()\n",
    "        ds = pd.read_csv(data_source)\n",
    "        info(\"Training data ingested in %s seconds.\" % (time.time() - start))\n",
    "\n",
    "        # Flush the stale training data from redis\n",
    "        self._r.flushdb()\n",
    "\n",
    "        start = time.time()\n",
    "        self._train(ds)\n",
    "        info(\"Engine trained in %s seconds.\" % (time.time() - start))\n",
    "\n",
    "    def _train(self, ds):\n",
    "        \"\"\"\n",
    "        Train the engine.\n",
    "\n",
    "        Create a TF-IDF matrix of unigrams, bigrams, and trigrams\n",
    "        for each product. The 'stop_words' param tells the TF-IDF\n",
    "        module to ignore common english words like 'the', etc.\n",
    "\n",
    "        Then we compute similarity between all products using\n",
    "        SciKit Leanr's linear_kernel (which in this case is\n",
    "        equivalent to cosine similarity).\n",
    "\n",
    "        Iterate through each item's similar items and store the\n",
    "        100 most-similar. Stops at 100 because well...  how many\n",
    "        similar products do you really need to show?\n",
    "\n",
    "        Similarities and their scores are stored in redis as a\n",
    "        Sorted Set, with one set for each item.\n",
    "\n",
    "        :param ds: A pandas dataset containing two fields: description & id\n",
    "        :return: Nothin!\n",
    "        \"\"\"\n",
    "\n",
    "        tf = TfidfVectorizer(analyzer='word',\n",
    "                             ngram_range=(1, 3),\n",
    "                             min_df=0,\n",
    "                             stop_words='english')\n",
    "        tfidf_matrix = tf.fit_transform(ds['description'])\n",
    "\n",
    "        cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "        for idx, row in ds.iterrows():\n",
    "            similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n",
    "            similar_items = [(cosine_similarities[idx][i], ds['id'][i])\n",
    "                             for i in similar_indices]\n",
    "\n",
    "            # First item is the item itself, so remove it.\n",
    "            # This 'sum' is turns a list of tuples into a single tuple:\n",
    "            # [(1,2), (3,4)] -> (1,2,3,4)\n",
    "            flattened = sum(similar_items[1:], ())\n",
    "            self._r.zadd(self.SIMKEY % row['id'], *flattened)\n",
    "\n",
    "    def predict(self, item_id, num):\n",
    "        \"\"\"\n",
    "        Couldn't be simpler! Just retrieves the similar items and\n",
    "        their 'score' from redis.\n",
    "\n",
    "        :param item_id: string\n",
    "        :param num: number of similar items to return\n",
    "        :return: A list of lists like: [[\"19\", 0.2203],\n",
    "        [\"494\", 0.1693], ...]. The first item in each sub-list is\n",
    "        the item ID and the second is the similarity score. Sorted\n",
    "        by similarity score, descending.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._r.zrange(self.SIMKEY % item_id,\n",
    "                              0,\n",
    "                              num-1,\n",
    "                              withscores=True,\n",
    "                              desc=True)\n",
    "\n",
    "content_engine = ContentEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists, and file is ok.\n"
     ]
    }
   ],
   "source": [
    "#include libraries\n",
    "import csv # to open/close/append CSV\n",
    "import os # to check if file exists\n",
    "import nltk #natural language toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter, defaultdict \n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "file_exists = os.path.isfile('/Users/boris/Downloads/dice_com-job_us_sample.csv')\n",
    "\n",
    "\n",
    "\n",
    "# loop to check if file exists\n",
    "if file_exists == 0:\n",
    "    print('Error: dice_com-job_us_sample.csv does not exist!')\n",
    "elif file_exists == 1:\n",
    "    try:\n",
    "        CSV_file = pd.read_csv('/Users/boris/Downloads/dice_com-job_us_sample.csv', sep=',', header='infer')\n",
    "        print('Exists, and file is ok.')\n",
    "    except Exception as e:\n",
    "        Date_Advertised = None\n",
    "        print('Exists, but failed to open.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def find_similar(tfidf_matrix, index, top_n = 5):\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n",
    "    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n",
    "    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]\n",
    "\n",
    "corpus = []\n",
    "for file in glob.glob(\"/Users/boris/Downloads/dice_com-job_us_sample.csv\"):\n",
    "    with open(file, \"r\") as paper:\n",
    "        corpus.append((file, paper.read()))\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,3), min_df = 0, stop_words = 'english')\n",
    "tfidf_matrix =  tf.fit_transform([content for file, content in corpus])\n",
    "\n",
    "with open(\"/Users/boris/Downloads/dice_com-job_us_sample.csv\", \"w\") as similarities_file:\n",
    "    writer = csv.writer(similarities_file, delimiter = \",\")\n",
    "\n",
    "    for me_index, item in enumerate(corpus):\n",
    "        similar_documents =  [(corpus[index], score) for index, score in find_similar(tfidf_matrix, me_index)]\n",
    "        me = corpus[me_index]\n",
    "\n",
    "        document_id = me[0].split(\"/\")[1].split(\".\")[0]\n",
    "\n",
    "        for ((raw_similar_document_id, title), score) in similar_documents:\n",
    "            similar_document_id = raw_similar_document_id.split(\"/\")[1].split(\".\")[0]\n",
    "            writer.writerow([document_id, me[1], similar_document_id, title, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-86f5eefcd404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    }
   ],
   "source": [
    "corpus[0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4649006)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
