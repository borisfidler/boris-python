{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#include libraries\n",
    "import csv # to open/close/append CSV\n",
    "import os # to check if file exists\n",
    "import nltk #natural language toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter, defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a job to search for: \n",
      "accounting\n"
     ]
    }
   ],
   "source": [
    "print('Please enter a job to search for: ')\n",
    "userInput = \"accounting\" #input()#'account'\n",
    "print(userInput)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_exists = os.path.isfile('/Users/boris/Downloads/data.csv')\n",
    "\n",
    "# loop to check if file exists\n",
    "if file_exists == 0:\n",
    "    print('Error: seek_data.csv does not exist!')\n",
    "elif file_exists == 1:\n",
    "    try:\n",
    "        CSV_buffer = pd.read_csv('/Users/boris/Downloads/data.csv', sep=',', header='infer')# read CSV file into buffer ################ for testing purposes (use \"Account\")\n",
    "    except Exception as e:\n",
    "        Date_Advertised = None\n",
    "        print('Exists, but failed to open.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userInput = str.lower(userInput)\n",
    "CSV_buffer2 = CSV_buffer.apply(lambda x: x.astype(str).str.lower())\n",
    "CSV_buffer2 = CSV_buffer2[CSV_buffer2['Main_Job_Title'].str.contains(userInput)] #case sensitive copy only matching rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "CSV_buffer2['Job_Description_Without_Stopwords'] = CSV_buffer2['Job_Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "def clean_string(strings):\n",
    "    result = []\n",
    "    for value in strings:\n",
    "        value = value.strip()\n",
    "        value = re.sub('([!?\\',.$])','', value)\n",
    "        value = re.sub(\"\\d+\", \"\", value)\n",
    "        result.append(value)\n",
    "    return result\n",
    "\n",
    "# creates list where each document is an element\n",
    "CSV_buffer2['Job_Description_Without_Stopwords'] = clean_string(CSV_buffer2['Job_Description_Without_Stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top skills for your searched job based on Term Frequency are:\n",
      "       count                index\n",
      "1371     16     accounts payable\n",
      "184      16      accounting firm\n",
      "611      14           high level\n",
      "575       9     attention detail\n",
      "469       8   accounting officer\n",
      "1711      8    experience within\n",
      "1040      7         provide high\n",
      "947       7  accounting practice\n",
      "464       7       please contact\n",
      "5094      7  bank reconciliation\n",
      "\n",
      "\n",
      "Top skills for your searched job based on addition of Inverse-Document Frequency are: \n",
      "                           index   vec_sum\n",
      "61              accounting firm  0.653326\n",
      "106            accounts payable  0.650798\n",
      "2031                 high level  0.510387\n",
      "74           accounting officer  0.452162\n",
      "1715         finance accounting  0.448008\n",
      "47    accounting administration  0.430251\n",
      "901        communication skills  0.396207\n",
      "4345      superannuation advice  0.394174\n",
      "4328      suitability statement  0.378011\n",
      "4798                 wide range  0.364312\n"
     ]
    }
   ],
   "source": [
    "bigram_list = []\n",
    "for index, row in CSV_buffer2.iterrows():\n",
    "    bigram_list = bigram_list + [b for b in nltk.bigrams(row['Job_Description_Without_Stopwords'].split())]\n",
    "\n",
    "# Bi-gram Term Frequency =======================================================================================================================================================================\n",
    "bigram_tf = Counter(bigram_list) # list all bigram TF\n",
    "bigram_tf_df = pd.DataFrame.from_dict(bigram_tf, orient='index').reset_index() #turn class collections.Counter into Pandas DataFrame\n",
    "bigram_tf_df = bigram_tf_df.rename(columns={'index':'index2', 0:'count'}) #index is immutable tuple and will need to be changed to list/string and cleaned to allow combining with IDF dataframe\n",
    "\n",
    "index_list = []\n",
    "for index, row in bigram_tf_df.iterrows():\n",
    "    index_list.append(str(row[0][0]) + ' ' + str(row[0][1]))\n",
    "\n",
    "bigram_tf_df['index'] = index_list\n",
    "bigram_tf_df = bigram_tf_df.drop(['index2'], axis=1) # delete bigram tuple column\n",
    "bigram_tf_df = bigram_tf_df.sort_values(by='count', ascending=False) #sort based on vec_sum\n",
    "\n",
    "# Bi-gram Inverse-Document Frequency ===========================================================================================================================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(2,2), min_df = 0, stop_words = 'english')\n",
    "TFIDF_terms = vectorizer.fit_transform(CSV_buffer2['Job_Description_Without_Stopwords']).toarray()\n",
    "TFIDF_df = pd.DataFrame(TFIDF_terms, columns=vectorizer.get_feature_names()) #pull terms into a dataframe\n",
    "IDF_df = TFIDF_df.T.reset_index() # rotate DataFrame\n",
    "IDF_df[IDF_df.columns[::-1]]\n",
    "IDF_df['vec_sum'] = IDF_df.sum(axis=1) #add column which is a sum of all other columns\n",
    "IDF_df = IDF_df.sort_values(by='vec_sum', ascending=False) #sort based on vec_sum\n",
    "IDF_TF = pd.DataFrame()\n",
    "IDF_TF = IDF_df[['index', 'vec_sum']].copy() #copy only the index and vector sum to the new dataframe\n",
    "\n",
    "# PRINT lists ==================================================================================================================================================================================\n",
    "print('\\nTop skills for your searched job based on Term Frequency are:\\n', bigram_tf_df.head(n=10)) # print dataframe\n",
    "\n",
    "print('\\n\\nTop skills for your searched job based on addition of Inverse-Document Frequency are: \\n', IDF_TF.head(n=10))# print only index and vec_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
